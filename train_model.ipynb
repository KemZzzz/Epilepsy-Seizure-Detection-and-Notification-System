{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import mne\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, filtfilt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Dense, Bidirectional, Conv1D, MaxPooling1D, Flatten, BatchNormalization, Attention\n",
    "from keras.optimizers import Adam"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "path='C:/Users/karme/Downloads/new_data_encoded/'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def load_emg_data(signals):\n",
    "    data = mne.io.read_raw_edf(signals, preload=True, verbose=False, encoding='latin1')\n",
    "    data.resample(1000)\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def emg_data_preprocessing(signals):\n",
    "    # Convert to DataFrame and select relevant columns\n",
    "    raw_data = signals.to_data_frame()\n",
    "    raw_data = raw_data.loc[:, ~raw_data.columns.str.startswith('time')]\n",
    "    raw_data = raw_data.iloc[:, -6:].to_numpy(dtype='float64')\n",
    "\n",
    "    # Bandpass filter (10-450 Hz)\n",
    "    low_band = 20 / 500\n",
    "    high_band = 450 / 500\n",
    "    a, b = butter(2, [low_band, high_band], btype='band')\n",
    "    emg_filtered = filtfilt(a, b, raw_data, method='gust')\n",
    "\n",
    "    # Rectify the signal\n",
    "    emg_rectified = np.abs(emg_filtered)\n",
    "    # Normalize the data\n",
    "    emg_normalized = (emg_rectified - np.mean(emg_rectified, axis=0)) / np.std(emg_rectified, axis=0)\n",
    "\n",
    "    return emg_normalized"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def get_datalabels(non_data, seizure_data, insert_col):\n",
    "    seizure_labels = [1] * len(seizure_data)\n",
    "    non_labels = [0] * len(non_data)\n",
    "\n",
    "    all_data = np.concatenate((non_data, seizure_data), axis = 0)\n",
    "    all_label = non_labels + seizure_labels\n",
    "\n",
    "    data_label = np.insert(all_data, insert_col, all_label, axis=1)\n",
    "    np.random.shuffle(data_label)\n",
    "\n",
    "    data_label = pd.DataFrame(data_label)\n",
    "\n",
    "    print(data_label)\n",
    "    sig , label = data_label.iloc[:, :-1], data_label.iloc[:, -1]\n",
    "\n",
    "    return sig , label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def splitting_data(sig , label):\n",
    "    oversampler = RandomOverSampler(\n",
    "        sampling_strategy=1.0, random_state=42\n",
    "    )\n",
    "    data_input_balanced, data_output_balanced = oversampler.fit_resample(\n",
    "        sig, label\n",
    "    )\n",
    "\n",
    "\n",
    "    '''\n",
    "    Split the data into training, validation and testing with ratios 60:20:20 respectively\n",
    "    '''\n",
    "    X, X_test, y, y_test = train_test_split(\n",
    "        data_input_balanced, data_output_balanced, test_size = 0.20, random_state = 42\n",
    "    )\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, test_size = 0.25, random_state = 0\n",
    "    )\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "       Signal  Non_start  Non_end  Seizure_start  Seizure_end\n0    P1.1.edf        120      150             54           68\n1    P1.2.edf        100      120             39           56\n2    P1.3.edf        126      140             65           76\n3    P1.4.edf        130      150             69           82\n4   P10.1.edf        116      130             53           66\n5   P10.2.edf        105      135             47           58\n6   P11.1.edf         50       70             26           48\n7   P11.2.edf        130      170             42           58\n8   P11.3.edf        100      130             25           40\n9   P12.1.edf        100      130             28           37\n10  P12.2.edf        110      140             25           50\n11  P13.1.edf        115      135             60           72\n12  P13.2.edf         80      100             27           38\n13  P13.3.edf        170      200             46           59\n14  P15.1.edf         75      100             27           42",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Signal</th>\n      <th>Non_start</th>\n      <th>Non_end</th>\n      <th>Seizure_start</th>\n      <th>Seizure_end</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>P1.1.edf</td>\n      <td>120</td>\n      <td>150</td>\n      <td>54</td>\n      <td>68</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>P1.2.edf</td>\n      <td>100</td>\n      <td>120</td>\n      <td>39</td>\n      <td>56</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>P1.3.edf</td>\n      <td>126</td>\n      <td>140</td>\n      <td>65</td>\n      <td>76</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>P1.4.edf</td>\n      <td>130</td>\n      <td>150</td>\n      <td>69</td>\n      <td>82</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>P10.1.edf</td>\n      <td>116</td>\n      <td>130</td>\n      <td>53</td>\n      <td>66</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>P10.2.edf</td>\n      <td>105</td>\n      <td>135</td>\n      <td>47</td>\n      <td>58</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>P11.1.edf</td>\n      <td>50</td>\n      <td>70</td>\n      <td>26</td>\n      <td>48</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>P11.2.edf</td>\n      <td>130</td>\n      <td>170</td>\n      <td>42</td>\n      <td>58</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>P11.3.edf</td>\n      <td>100</td>\n      <td>130</td>\n      <td>25</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>P12.1.edf</td>\n      <td>100</td>\n      <td>130</td>\n      <td>28</td>\n      <td>37</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>P12.2.edf</td>\n      <td>110</td>\n      <td>140</td>\n      <td>25</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>P13.1.edf</td>\n      <td>115</td>\n      <td>135</td>\n      <td>60</td>\n      <td>72</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>P13.2.edf</td>\n      <td>80</td>\n      <td>100</td>\n      <td>27</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>P13.3.edf</td>\n      <td>170</td>\n      <td>200</td>\n      <td>46</td>\n      <td>59</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>P15.1.edf</td>\n      <td>75</td>\n      <td>100</td>\n      <td>27</td>\n      <td>42</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Start_End=pd.read_csv('Start_End.csv')\n",
    "Start_End=Start_End.loc[:,~Start_End.columns.str.startswith('Unnamed: 0')]\n",
    "Start_End"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:30<00:00,  2.02s/it]\n"
     ]
    }
   ],
   "source": [
    "all_seizure_data = []\n",
    "all_non_data = []\n",
    "\n",
    "for i in tqdm(range(len(Start_End.index))):\n",
    "    temp = str(Start_End.iloc[i, 0])\n",
    "    file = load_emg_data(path + temp)\n",
    "    preprocessed = emg_data_preprocessing(file)\n",
    "\n",
    "\n",
    "    Nonstart_time = (Start_End.iloc[i, 1])*1024\n",
    "    Nonend_time = (Start_End.iloc[i, 2])*1024\n",
    "    Seizurestart_time = (Start_End.iloc[i, 3])*1024\n",
    "    Seizureend_time = (Start_End.iloc[i, 4])*1024\n",
    "\n",
    "\n",
    "    non_data = preprocessed[:][Nonstart_time:Nonend_time]\n",
    "    seizure_data = preprocessed[:][Seizurestart_time:Seizureend_time]\n",
    "\n",
    "    all_seizure_data.append(pd.DataFrame(seizure_data))\n",
    "    all_non_data.append(pd.DataFrame(non_data))\n",
    "\n",
    "all_seizure_data = pd.concat(all_seizure_data, ignore_index=True)\n",
    "all_non_data = pd.concat(all_non_data, ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               0         1         2         3         4         5    6\n",
      "0       0.105276  1.550028  0.101586  0.195083  0.987401  3.288814  1.0\n",
      "1       5.518878 -0.168667  3.052647 -0.451323 -0.171620  1.252200  0.0\n",
      "2       1.573374 -0.437759  0.378517  3.318596  0.178550  0.100831  1.0\n",
      "3       1.570637  2.316245  4.387606  1.193490  9.571342  2.430719  1.0\n",
      "4      -0.426869 -0.453103  0.197178  0.392171  1.132225 -0.362813  0.0\n",
      "...          ...       ...       ...       ...       ...       ...  ...\n",
      "604155 -0.447926 -0.586444 -0.427571 -0.520714 -0.490685 -0.667375  0.0\n",
      "604156  1.266325 -0.352104  3.590747  0.413340  1.077991  0.236407  1.0\n",
      "604157 -0.839811 -0.097092 -0.766393 -0.711786 -0.312977 -0.488010  0.0\n",
      "604158 -0.085439  0.372500 -0.740664  0.621390 -0.415309 -0.334758  1.0\n",
      "604159  2.695051 -0.674836  5.716072 -0.708466  1.675557  1.821291  1.0\n",
      "\n",
      "[604160 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "sig , label = get_datalabels(all_non_data, all_seizure_data, 6)\n",
    "# print(label.value_counts())\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = splitting_data(sig , label)\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='best-model/best_model.weights.h5',\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "X_train_array = X_train.to_numpy()\n",
    "X_val_array = X_val.to_numpy()\n",
    "X_test_array = X_test.to_numpy()\n",
    "\n",
    "# Reshape the input data\n",
    "X_train_reshaped = X_train_array.reshape((X_train_array.shape[0], 1, X_train_array.shape[1]))\n",
    "X_val_reshaped = X_val_array.reshape((X_val_array.shape[0], 1, X_val_array.shape[1]))\n",
    "X_test_reshaped = X_test_array.reshape((X_test_array.shape[0], 1, X_test_array.shape[1]))\n",
    "\n",
    "y_train_reshaped = np.expand_dims(y_train, axis=1)\n",
    "y_val_reshaped = np.expand_dims(y_val, axis=1)\n",
    "y_test_reshaped = np.expand_dims(y_test, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Additional and Different Layers:\n",
    "Convolutional Layers: Convolutional Neural Networks (CNNs) are excellent at capturing spatial hierarchies in data. Adding a few convolutional layers before the LSTM layers can help in capturing local patterns in the EMG signals.\n",
    "More LSTM Layers: Adding more LSTM layers can help capture more complex temporal dependencies in the data.\n",
    "Attention Mechanism: Integrating attention layers can help the model focus on the most relevant parts of the input sequence.\n",
    "Batch Normalization: Adding batch normalization can help stabilize and accelerate the training process.\n",
    "## 2. Data Augmentation:\n",
    "Noise Injection: Adding noise to the EMG signals during training can make the model more robust.\n",
    "Signal Transformation: Applying various transformations such as scaling, shifting, and jittering can help the model generalize better.\n",
    "## 3. Hyperparameter Tuning:\n",
    "Experiment with different numbers of LSTM units, dropout rates, learning rates, and batch sizes.\n",
    "## 4. Regularization:\n",
    "Dropout: Consider increasing the dropout rate or applying dropout to more layers to prevent overfitting.\n",
    "L2 Regularization: Add L2 regularization to the dense layers.\n",
    "## 5. Model Evaluation:\n",
    "Use a more comprehensive evaluation metric, such as the F1 score, precision, recall, or the area under the ROC curve (AUC-ROC).\n",
    "## Summary of Changes:\n",
    "Added Conv1D Layers: To capture spatial features in the EMG signals.\n",
    "Batch Normalization: To stabilize and accelerate training.\n",
    "Dropout Increased: To prevent overfitting.\n",
    "Regularization in Dense Layer: To further prevent overfitting.\n",
    "AUC Metric: Added as an additional evaluation metric.\n",
    "## Further Steps:\n",
    "Cross-Validation: Use cross-validation to evaluate the model performance.\n",
    "Experimentation: Experiment with different architectures and hyperparameters to find the best model configuration for your specific data and task.\n",
    "These changes should help improve the performance and robustness of your model for detecting convulsive seizures from EMG signals."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "14322/14324 [============================>.] - ETA: 0s - loss: 0.3040 - accuracy: 0.8825 - auc: 0.9476\n",
      "Epoch 1: val_loss improved from inf to 0.26319, saving model to best-model\\best_model.weights.h5\n",
      "14324/14324 [==============================] - 106s 7ms/step - loss: 0.3040 - accuracy: 0.8825 - auc: 0.9476 - val_loss: 0.2632 - val_accuracy: 0.9027 - val_auc: 0.9623\n",
      "Epoch 2/10\n",
      "14318/14324 [============================>.] - ETA: 0s - loss: 0.2562 - accuracy: 0.9069 - auc: 0.9624\n",
      "Epoch 2: val_loss improved from 0.26319 to 0.22584, saving model to best-model\\best_model.weights.h5\n",
      "14324/14324 [==============================] - 98s 7ms/step - loss: 0.2563 - accuracy: 0.9069 - auc: 0.9624 - val_loss: 0.2258 - val_accuracy: 0.9207 - val_auc: 0.9701\n",
      "Epoch 3/10\n",
      "14321/14324 [============================>.] - ETA: 0s - loss: 0.2366 - accuracy: 0.9176 - auc: 0.9677\n",
      "Epoch 3: val_loss improved from 0.22584 to 0.20991, saving model to best-model\\best_model.weights.h5\n",
      "14324/14324 [==============================] - 97s 7ms/step - loss: 0.2367 - accuracy: 0.9176 - auc: 0.9677 - val_loss: 0.2099 - val_accuracy: 0.9295 - val_auc: 0.9744\n",
      "Epoch 4/10\n",
      "14321/14324 [============================>.] - ETA: 0s - loss: 0.2236 - accuracy: 0.9250 - auc: 0.9709\n",
      "Epoch 4: val_loss improved from 0.20991 to 0.19805, saving model to best-model\\best_model.weights.h5\n",
      "14324/14324 [==============================] - 99s 7ms/step - loss: 0.2236 - accuracy: 0.9250 - auc: 0.9709 - val_loss: 0.1980 - val_accuracy: 0.9353 - val_auc: 0.9770\n",
      "Epoch 5/10\n",
      "14319/14324 [============================>.] - ETA: 0s - loss: 0.2156 - accuracy: 0.9292 - auc: 0.9727\n",
      "Epoch 5: val_loss improved from 0.19805 to 0.18847, saving model to best-model\\best_model.weights.h5\n",
      "14324/14324 [==============================] - 102s 7ms/step - loss: 0.2156 - accuracy: 0.9292 - auc: 0.9727 - val_loss: 0.1885 - val_accuracy: 0.9400 - val_auc: 0.9788\n",
      "Epoch 6/10\n",
      "14322/14324 [============================>.] - ETA: 0s - loss: 0.2088 - accuracy: 0.9326 - auc: 0.9743\n",
      "Epoch 6: val_loss improved from 0.18847 to 0.18421, saving model to best-model\\best_model.weights.h5\n",
      "14324/14324 [==============================] - 102s 7ms/step - loss: 0.2088 - accuracy: 0.9326 - auc: 0.9743 - val_loss: 0.1842 - val_accuracy: 0.9418 - val_auc: 0.9794\n",
      "Epoch 7/10\n",
      "14322/14324 [============================>.] - ETA: 0s - loss: 0.2048 - accuracy: 0.9343 - auc: 0.9751\n",
      "Epoch 7: val_loss improved from 0.18421 to 0.17975, saving model to best-model\\best_model.weights.h5\n",
      "14324/14324 [==============================] - 102s 7ms/step - loss: 0.2048 - accuracy: 0.9343 - auc: 0.9751 - val_loss: 0.1798 - val_accuracy: 0.9447 - val_auc: 0.9800\n",
      "Epoch 8/10\n",
      "14321/14324 [============================>.] - ETA: 0s - loss: 0.1998 - accuracy: 0.9369 - auc: 0.9761\n",
      "Epoch 8: val_loss improved from 0.17975 to 0.17677, saving model to best-model\\best_model.weights.h5\n",
      "14324/14324 [==============================] - 99s 7ms/step - loss: 0.1998 - accuracy: 0.9369 - auc: 0.9761 - val_loss: 0.1768 - val_accuracy: 0.9458 - val_auc: 0.9805\n",
      "Epoch 9/10\n",
      "14318/14324 [============================>.] - ETA: 0s - loss: 0.1968 - accuracy: 0.9379 - auc: 0.9767\n",
      "Epoch 9: val_loss improved from 0.17677 to 0.17327, saving model to best-model\\best_model.weights.h5\n",
      "14324/14324 [==============================] - 103s 7ms/step - loss: 0.1968 - accuracy: 0.9379 - auc: 0.9767 - val_loss: 0.1733 - val_accuracy: 0.9474 - val_auc: 0.9809\n",
      "Epoch 10/10\n",
      "14322/14324 [============================>.] - ETA: 0s - loss: 0.1946 - accuracy: 0.9390 - auc: 0.9771\n",
      "Epoch 10: val_loss improved from 0.17327 to 0.16920, saving model to best-model\\best_model.weights.h5\n",
      "14324/14324 [==============================] - 97s 7ms/step - loss: 0.1946 - accuracy: 0.9390 - auc: 0.9771 - val_loss: 0.1692 - val_accuracy: 0.9485 - val_auc: 0.9817\n"
     ]
    }
   ],
   "source": [
    "input_shape=(1, 6)\n",
    "\n",
    "model = Sequential()\n",
    "# Bidirectional LSTM layers\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Bidirectional(LSTM(128)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Dense layer with L2 regularization\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy', 'AUC'])\n",
    "\n",
    "\n",
    "history = model.fit(X_train_reshaped, y_train_reshaped, epochs=10, batch_size=32, validation_data=(X_val_reshaped, y_val_reshaped), verbose=1, callbacks=[checkpoint])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4775/4775 [==============================] - 9s 2ms/step - loss: 0.1711 - accuracy: 0.9481 - auc: 0.9814\n",
      "Test Loss: 0.1711205542087555\n",
      "Test Accuracy: 0.9480628967285156\n",
      "Test AUC: 0.9814354181289673\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy, auc = model.evaluate(X_test_reshaped, y_test_reshaped)\n",
    "print(f'Test Loss: {loss}')\n",
    "print(f'Test Accuracy: {accuracy}')\n",
    "print(f'Test AUC: {auc}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}